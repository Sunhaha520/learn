---
title: 人脸识别系统
date: 2021-10-11 17:32:25
tags: 计算机视觉
categories: 学习笔记
cover: https://s.pc.qq.com/tousu/img/20211011/5975319_1633944817.jpg
---

# 前言

{% note warning flat %} 重要的事情说三遍：我是菜鸡！我是菜鸡！我是菜鸡！{% endnote %}

因为我是一个菜鸡{% inlineimage https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji@1.0.0/aru-l/0340.gif %}，所以技术很菜，如果有不对的地方还请多多指正，阴阳怪气解决不了问题，也不要拿着一个错别字来给我敲黑板，我写博客本来就是给自己学习巩固看的，不是展示给别人的，为什么我要重复这点呢？之前的博客因为遇到了几个恶心人整的我不想写了。一个词不小心打错整的他可得意了，不依不饶的。{% inlineimage https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji@1.0.0/aru-l/8091.gif %}

在这个项目中，主要学习了如何运用OpenCV进行高精度的面部识别。在简要地理论学习之后。我创建一个考勤的小项目，这个项目使用笔记本自带的摄像头进行人脸检测，并在excel表格中实时记录考勤数据。

#  实施过程

##  一些想法

小时候看过不少科幻电影，看到警察追踪犯人调用满街的摄像头，绿色框框所到之处都显示着圈出人的详细信息，这个画面真的帅。

{% image https://s.pc.qq.com/tousu/img/20211011/9129020_1633955804.jpg, width=500px %}

那么，如何去实现一个简单的人脸识别呢？

##  前期准备

|   cmake   |       dlib        | face_recognition  |
| :-------: | :---------------: | :---------------: |
| **numpy** | **opencv-python** | **Pycharm(工具)** |

{% note danger flat %}强烈建议安装版本为19.18.0的dlib{% endnote %}

##  了解难题

虽然许多人脸识别算法已经发展了多年，但它们的速度和精度平衡一直不是最优的。但最近的一些进展让我们看到了希望。一个很好的例子就是Facebook，他们可以用一些训练图片来标记你和你的朋友，准确率高达98%。至于工作原理，我尝试用亚当·盖特吉开发的面部识别库来进行探索。

{% span blue, 人脸识别如今面临的几个问题: %}

{% checkbox red checked, 能在一张照片里准确找到人的脸部 %}
{% checkbox green checked, 能够更准确识别脸部，即使脸部发生转向或者在光线较差地方 %}
{% checkbox yellow checked, 能够进行快速比较 %}
{% checkbox cyan checked, 当代中国P图化妆女性脸部识别 %}

##  实现过程

###  引入

首先，我们将导入相关的库，于是，识别过程就可分为3个步骤。

```python
import face_recognition
import cv2
import numpy as np
```

###  第一步：加载图像并转换为RGB

加载图像是人脸识别系统重要的组成部分，一旦加载或导入，图像必须转换为RGB形式。

```python
imgElon = face_recognition.load_image_file('ImagesBasic/Elon Musk.jpg')#导入图片，路径自定
imgElon = cv2.cvtColor(imgElon,cv2.COLOR_BGR2RGB)
imgTest = face_recognition.load_image_file('ImagesBasic/Elon Test.jpg')
imgTest = cv2.cvtColor(imgTest,cv2.COLOR_BGR2RGB)#转换
```

{% folding green,导入的图片 %}

![](https://s.pc.qq.com/tousu/img/20211011/6198404_1633957923.jpg)

{% endfolding %}

###  第二步：查找面孔位置和编码

在第二步中，我们将使用人脸识别库的真正功能。首先，我们将在我们导入的图像中找到面孔。这是使用HOG(面向梯度的直方图)在后台完成的。一旦我们有了导入图片中脸的信息，他们将会被扭曲，以消除旋转带来的误差。然后将图像输入预先训练的神经网络，神经网络会输出128个针对这张脸的测量值。模型测量的部分并不为人所知，因为这是模型在训练时自己学习的。我们只需要用几行代码就可以完成了。一旦我们有了脸的位置和编码，我们就可以在脸周围画出矩形。

```python
faceLoc = face_recognition.face_locations(imgElon)[0]
encodeElon = face_recognition.face_encodings(imgElon)[0]
cv2.rectangle(imgElon, (faceLoc[3], faceLoc[0]), (faceLoc[1], faceLoc[2]), (0, 255, 0), 2)  # top, right, bottom, left

faceLocTest = face_recognition.face_locations(imgTest)[0]
encodeTest = face_recognition.face_encodings(imgTest)[0]
cv2.rectangle(imgTest, (faceLocTest[3], faceLocTest[0]), (faceLocTest[1], faceLocTest[2]), (255, 0, 255), 2)
```

{% folding red,识别加框 %}

![](https://s.pc.qq.com/tousu/img/20211011/2595647_1633958870.jpg)

{% endfolding %}

###  第三步：比较面部和发现差距

一旦我们有了这两张脸的编码，我们就可以比较这张脸的128个测量值来寻找相似之处。我们可以使用compare_faces函数来查找这些faces是否匹配。该函数返回True或False。类似地，我们可以使用face_distance函数来确定人脸在数字上匹配的可能性。

```python
results = face_recognition.compare_faces([encodeElon], encodeTest)
faceDis = face_recognition.face_distance([encodeElon], encodeTest)
cv2.putText(imgTest, f'{results} {round(faceDis[0], 2)}', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 255), 3)
```

如果我们用测试图像运行这个，我们得到的值是Flase，表明发现的脸不是埃隆·马斯克的。面之间的差值是0.72。差值越小，匹配越好。越大，越不像。

{% folding 对比测试 %}

<img src="https://s.pc.qq.com/tousu/img/20211011/8340535_1633960385.jpg" style="zoom:80%;" />

{% endfolding %}

###    完整代码

{% folding blue, 完整代码 %}

```python
import face_recognition
import cv2
import numpy as np

imgElon = face_recognition.load_image_file('ImagesBasic/Elon Musk.jpg')
imgElon = cv2.cvtColor(imgElon, cv2.COLOR_BGR2RGB)
imgTest = face_recognition.load_image_file('ImagesBasic/Elon Test.jpg')
imgTest = cv2.cvtColor(imgTest, cv2.COLOR_BGR2RGB)

faceLoc = face_recognition.face_locations(imgElon)[0]
encodeElon = face_recognition.face_encodings(imgElon)[0]
cv2.rectangle(imgElon, (faceLoc[3], faceLoc[0]), (faceLoc[1], faceLoc[2]), (0, 255, 0), 2)  # top, right, bottom, left

faceLocTest = face_recognition.face_locations(imgTest)[0]
encodeTest = face_recognition.face_encodings(imgTest)[0]
cv2.rectangle(imgTest, (faceLocTest[3], faceLocTest[0]), (faceLocTest[1], faceLocTest[2]), (255, 0, 255), 2)

results = face_recognition.compare_faces([encodeElon], encodeTest)
faceDis = face_recognition.face_distance([encodeElon], encodeTest)
cv2.putText(imgTest, f'{results} {round(faceDis[0], 2)}', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 255), 3)

cv2.imshow("Elon Musk", imgElon)
cv2.imshow("Elon Test", imgTest)
cv2.waitKey(0)
```

{% endfolding %}



##  面部识别考勤系统

现在，使用我们在上面看到的方法，我们将开发一个考勤系统，当用户在相机中被检测到时，该系统将自动记录用户的信息。我们将存储名称以及他们出现的时间。

###  导入图片

就像我们之前导入的一样，我们可以使用相同的face_recognition.load_image_file()函数来导入图像。但是当我们有多个图像时，单独导入它们会很麻烦。因此，我们将编写一个脚本来一次性导入给定文件夹中的所有图像。为此，我们将需要os库，所以我们将首先导入它。我们将在一个列表中存储所有图像，在另一个列表中存储它们的名称。

```python
import face_recognition
import cv2
import numpy as np
import os
```

```python
path = 'ImagesAttendance'
images = []     # 包含所有图像的列表
className = []    # 包含所有对应类名的列表
myList = os.listdir(path)
print("Total Classes Detected:",len(myList))
for x,cl in enumerate(myList):
        curImg = cv2.imread(f'{path}/{cl}')
        images.append(curImg)
        className.append(os.path.splitext(cl)[0])
```

###  计算编码

现在我们有了一个图像列表，我们可以遍历这些图像，并为已知的面孔创建相应的编码列表。为此，我们将创建一个函数。如前所述，我们将首先将其转换为RGB，然后使用face_encodings()函数查找其编码。然后将每个编码添加到列表中。

```python
def findEncodings(images):
    encodeList = []
    for img in images:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        encode = face_recognition.face_encodings(img)[0]
        encodeList.append(encode)
    return encodeList
```

现在我们可以简单地用图像列表作为输入参数调用这个函数。

```python
encodeListKnown = findEncodings(images)
print('Encodings Complete')
```

![](https://s.pc.qq.com/tousu/img/20211011/8615713_1633964762.jpg)

###  While循环

创建while循环来运行网络摄像头。但是在while循环之前，我们必须创建一个视频捕捉对象，这样我们就可以从网络摄像机中抓取帧。

```python
cap = cv2.VideoCapture(0)
```

####  获取网络摄像头图像

首先，我们将从网络摄像头读取图像，然后调整它的大小为四分之一。这样做是为了提高系统的速度。即使使用的图像是原来的1/4，我们仍然会在显示时使用原来的尺寸。接下来我们将把它转换为RGB。

```python
while True:
    success, img = cap.read()
    imgS = cv2.resize(img, (0, 0), fx=0.25, fy=0.25)
    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)
```

####  摄像头编码

一旦我们有了摄像头框架，我们就会在图像中找到所有的脸。face_locations函数用于此处起到了重要作用。稍后我们也会找到face_encodings。

```python
facesCurFrame = face_recognition.face_locations(imgS)
encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)
```

###  找到匹配

现在，我们可以将当前的面孔编码与已知的面孔编码列表进行匹配，以找到匹配的面孔。我们还要计算差值。这样做是为了在一次检测到多个面时找到最佳匹配。

```python
for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):
    matches = face_recognition.compare_faces(encodeListKnown, encodeFace)
    faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)
```

一旦我们有了人脸距离列表，我们就可以找到最小差值，因为这将是最好的匹配。

```python
matchIndex = np.argmin(faceDis)
```

现在，根据索引值，我们可以确定人员的名称，并将其显示在原始Image上。

```python
if matches[matchIndex]:
    name = className[matchIndex].upper()
    y1,x2,y2,x1=faceLoc
    y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4
    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)
    cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)
```

![](https://s.pc.qq.com/tousu/img/20211011/6433332_1633965731.jpg)

###  记录出席

最后，我们将添加自动考勤代码。我们将从编写一个只需要一个输入即用户名的函数开始。首先，我们打开我们的出席文件，这是在csv格式。然后我们读取所有的行，并使用for循环遍历每一行。接下来我们可以用逗号分隔。这将允许我们获得第一个元素，即用户名。如果相机中的用户已经在文件中有一个条目，那么什么也不会发生。另一方面，如果用户是新用户，则会存储该用户的名称以及当前时间戳。我们可以使用datetime包中的datetime类来获取当前时间。

{% note success flat %}要新建一个csv文件，文件内写上name,time{% endnote %}

```
def markAttendance(name):
    with open('Attendance.csv','r+') as f:
        myDataList = f.readlines()
        nameList =[]
        for line in myDataList:
            entry = line.split(',')
            nameList.append(entry&amp;#91;0])
        if name not in  line:
            now = datetime.now()
            dt_string = now.strftime("%H:%M:%S")
            f.writelines(f'n{name},{dt_string}')
```

###  完整代码

{% folding 完整代码 %}

```python
import face_recognition
import cv2
import numpy as np
import os
from datetime import datetime

path = 'ImagesAttendance'
images = []
classNames = []
myList = os.listdir(path)
print(myList)
for cl in myList:
    curImg = cv2.imread(f'{path}/{cl}')
    images.append(curImg)
    classNames.append(os.path.splitext(cl)[0])
print(classNames)


def findEncodings(images):
    encodeList = []
    for img in images:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        encode = face_recognition.face_encodings(img)[0]
        encodeList.append(encode)
    return encodeList


def markAttendance(name):
    with open('Attendance.csv', 'r+') as f:
        myDataList = f.readline()
        nameList = []
        for line in myDataList:
            entry = line.split(',')
            nameList.append(entry[0])
        if name not in nameList:
            now = datetime.now()
            dtString = now.strftime('%H:%M:%S')
            f.writelines(f'\n{name},{dtString}')


markAttendance('a')

encodeListKnown = findEncodings(images)
print("Encoding Complete")

cap = cv2.VideoCapture(0)

while True:
    success, img = cap.read()
    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)
    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)

    facesCurFrame = face_recognition.face_locations(imgS)
    encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)

    for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):
        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)
        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)
        # print(faceDis)
        matchIndex = np.argmin(faceDis)

        if matches[matchIndex]:
            name = classNames[matchIndex].upper()
            # print(name)
            y1, x2, y2, x1 = faceLoc
            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)
            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 225, 225), 2)
            markAttendance(name)

    cv2.imshow('Webcam', img)
    cv2.waitKey(1)
```

{% endfolding %}

###  补充

####  标记未知的面孔

把下面代码

```python
if matches[matchIndex]:
    name = classNames[matchIndex].upper()
    #print(name)
    y1,x2,y2,x1 = faceLoc
    y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4
    cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)
    cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)
    cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)
    markAttendance(name)
```

替换成如下

```python
if faceDis[matchIndex]&lt; 0.50:
    name = classNames[matchIndex].upper()
    markAttendance(name)
else: name = 'Unknown'
#print(name)
y1,x2,y2,x1 = faceLoc
y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4
cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)
cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)
cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)
```

这样做是为了检查到最小差值是否小于0.5。如果不是，那么这意味着这个人是未知的，所以我们把名字改为未知，不标记出席。
